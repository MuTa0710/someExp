{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af8148c",
   "metadata": {},
   "source": [
    "# Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f3ccf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch import repeat_interleave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3966833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention(nn.Module):\n",
    "    def __init__(self, input_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding_dim = input_dim\n",
    "        self.attention_dim = input_dim\n",
    "        self.q = nn.Linear(self.embedding_dim, self.attention_dim)\n",
    "        self.k = nn.Linear(self.embedding_dim, self.attention_dim)\n",
    "        self.v = nn.Linear(self.embedding_dim, self.attention_dim)\n",
    "    def forward(self, x):# x.shape = bs, seqlen, input_dim \n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        scores = torch.bmm(q, k.transpose(1, 2)) / math.sqrt(self.attention_dim)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        out = torch.bmm(weights, v)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf5d0b",
   "metadata": {},
   "source": [
    "## 代码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8289ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([2, 10, 64])\n",
      "out.shape: torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "bs, seqlen, input_dim = 2, 10, 64\n",
    "x = torch.rand(bs, seqlen, input_dim)\n",
    "attn = self_attention(input_dim)\n",
    "output = attn(x)\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"out.shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a939c49",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae438db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "    def __init__(self, head, input_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.head = head\n",
    "        assert self.input_dim % self.head == 0\n",
    "        self.attn_dim = self.input_dim // head\n",
    "        self.wq = nn.Linear(self.input_dim, self.attn_dim * self.head)\n",
    "        self.wk = nn.Linear(self.input_dim, self.attn_dim * self.head)\n",
    "        self.wv = nn.Linear(self.input_dim, self.attn_dim * self.head)\n",
    "\n",
    "        self.out = nn.Linear(self.input_dim, self.attn_dim * self.head)# 使用一个投影层整合每个头之间的信息\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, seq, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        xq = xq.view(bs, seq, self.head, self.attn_dim).transpose(1, 2)\n",
    "        xk = xk.view(bs, seq, self.head, self.attn_dim).transpose(1, 2)\n",
    "        xv = xv.view(bs, seq, self.head, self.attn_dim).transpose(1, 2)\n",
    "        # xv.shape : bs, seq, head, attn_dim\n",
    "        scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.attn_dim) # bs, head, seq, seq\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(weights, xv) # bs, head, seq, attn_dim\n",
    "        out = out.transpose(1, 2).contiguous().view(bs, seq, -1)\n",
    "        # 这里必须调用.contiguous()，因为.view()方法需要内存空间中连续的tensor，而.transpose()方法会使得原本的tensor变得不连续\n",
    "        return self.out(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed5db9",
   "metadata": {},
   "source": [
    "## 代码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a301708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([2, 10, 64])\n",
      "out.shape: torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "bs, seqlen, head, input_dim = 2, 10, 8, 64\n",
    "x = torch.rand(bs, seqlen, input_dim)\n",
    "mha = MHA(head, input_dim)\n",
    "output = mha(x)\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"out.shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb955c",
   "metadata": {},
   "source": [
    "# Grouped Multi-Query Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GQA(nn.Module):\n",
    "    def __init__(self, head, input_dim, kv_heads) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.head = head\n",
    "        assert self.input_dim % self.head == 0\n",
    "        self.head_dim = self.input_dim // self.head\n",
    "        self.kv_heads = kv_heads\n",
    "        assert self.head % self.kv_heads == 0\n",
    "        self.group = self.head // self.kv_heads\n",
    "        self.wq = nn.Linear(self.input_dim, self.head_dim * self.head)\n",
    "\n",
    "        self.wk = nn.Linear(self.input_dim, self.head_dim * self.kv_heads)# 这里头的数量不再是head，而是kv_heads,即将Q分为了self.group个组\n",
    "        self.wv = nn.Linear(self.input_dim, self.head_dim * self.kv_heads)\n",
    "\n",
    "        self.wo = nn.Linear(self.input_dim, self.head_dim * self.head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, seq, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        xq = xq.view(bs, seq, self.head, self.head_dim).transpose(1, 2)\n",
    "        xk = xk.view(bs, seq, self.kv_heads, self.head_dim).transpose(1, 2)\n",
    "        xv = xv.view(bs, seq, self.kv_heads, self.head_dim).transpose(1, 2)\n",
    "        # bs head seq head_dim\n",
    "        xk = xk.repeat_interleave(self.group, dim=1)\n",
    "        xv = xv.repeat_interleave(self.group, dim=1)\n",
    "        scores = torch.matmul(xq, xk.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(weights, xv)\n",
    "        out = out.transpose(1, 2).contiguous().view(bs, seq, -1)\n",
    "        return self.wo(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af3b81",
   "metadata": {},
   "source": [
    "## 代码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef721",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq, input_dim, kv_heads, head = 2, 10, 64, 4, 8\n",
    "x = torch.rand(bs, seq, input_dim)\n",
    "gqa = GQA(head, input_dim, kv_heads)\n",
    "out = gqa(x)\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"out.shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e9df1",
   "metadata": {},
   "source": [
    "### 值得注意的点\n",
    "\n",
    "        xk = xk.repeat_interleave(self.group, dim=1)\n",
    "        xv = xv.repeat_interleave(self.group, dim=1)\n",
    "\n",
    "这里使用了.repeat_interleave()函数来对输入数据的指定维度进行拷贝，这是实现复制的第一种方式。\n",
    "\n",
    "另一种方式是：\n",
    "\n",
    "        # xk: (bs, kv_heads, seq, head_dim)\n",
    "        xk = xk.unsqueeze(2)  # (bs, kv_heads, 1, seq, head_dim)\n",
    "        xk = xk.expand(-1, -1, self.group, -1, -1)  # (bs, kv_heads, group, seq, head_dim)\n",
    "        xk = xk.reshape(bs, -1, seq, self.head_dim)  # (bs, head, seq, head_dim)\n",
    "\n",
    "这里分别给出unsqueeze， expand， reshape三个函数的作用：\n",
    "\n",
    "1. **unsqueeze()**: 用于在指定维度前面添加一个为大小1的维度，一般用于维度的增加；\n",
    "2. **expand()**: 用于扩展数量为1的维度的数量，并且不复制数据；\n",
    "3. **reshape()**: 重组tensor形状，当tensor连续时不复制数据，不连续时复制数据；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcd75680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "363e0a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(2, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12daf551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[5, 6, 7, 8],\n",
       "         [5, 6, 7, 8]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(1)\n",
    "x = x.expand(-1, 2, -1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(16)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLaMa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
